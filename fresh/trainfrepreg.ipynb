{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7287c22-b9f5-4e1e-a696-1040fd7d5c92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/louisayu/nfs_share2/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n",
      "2024-03-06 22:36:32.575429: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-06 22:36:36.327316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36591 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c7:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow_addons as tfa\n",
    "#import keras\n",
    "import time\n",
    "#time.sleep(60*60*8)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, regularizers, layers, optimizers, losses, metrics\n",
    "from tensorflow.keras.layers import Input, Concatenate, Conv2D, Flatten, Dense, Add, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator,array_to_img\n",
    "from keras import backend\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_score, recall_score, classification_report, ConfusionMatrixDisplay, roc_auc_score, matthews_corrcoef,plot_roc_curve,roc_curve,average_precision_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "from skimage import data, color, img_as_ubyte ,io\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import hough_ellipse\n",
    "from skimage.draw import ellipse_perimeter\n",
    "from skimage.color import rgb2gray,rgba2rgb\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import mode\n",
    "import imutils\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "import random\n",
    "import urllib.request\n",
    "from vit_keras import vit\n",
    "\n",
    "\n",
    "def decodepreg(i):\n",
    "    if i==6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "tf.keras.backend.clear_session()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b8174f-df66-4253-9c26-5bdde966dcba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423 1010\n"
     ]
    }
   ],
   "source": [
    "preglist=os.listdir('/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/')\n",
    "pixel=256\n",
    "pixel1=256\n",
    "pixel2=192\n",
    "channels=3\n",
    "NUM_CLASSES=2\n",
    "train_image=[]\n",
    "train_label=[]\n",
    "\n",
    "for f in preglist:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    for j in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][j]\n",
    "        if not p['POutc'][j]==8:\n",
    "            try:\n",
    "                im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "                im = cv2.resize(im,(pixel,pixel))\n",
    "                im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "                #im = cv2.copyMakeBorder(im, 32, 32, 0, 0, cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "                img = img_to_array(im)\n",
    "                train_image.append(img)\n",
    "                train_label.append(decodepreg(p['POutc'][j]))\n",
    "            except:\n",
    "                print(filename)\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2853b776-f8b8-4456-91e3-e61aaa593ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████████████████████▋| 473/476 [00:23<00:00, 25.11it/s][ WARN:0@378.139] global loadsave.cpp:248 findDecoder imread_('/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/20220501 LKM.jpg'): can't open/read file: check file path/integrity\n",
      "100%|███████████████████████████████████████████████████████| 476/476 [00:23<00:00, 20.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/20220501 LKM.jpg\n",
      "306 169\n",
      "StratifiedKFold(n_splits=10, random_state=27, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "freset= pd.read_csv('/mnt/louisayu/nfs_share2/embryo/code/em_aug/matched_fre_correct.csv')  \n",
    "pixel=256\n",
    "pixel1=256\n",
    "pixel2=192\n",
    "channels=3\n",
    "NUM_CLASSES=2\n",
    "fine_image=[]\n",
    "fine_label=[]\n",
    "# g1=[]\n",
    "# g2=[]\n",
    "# g3=[]\n",
    "\n",
    "for i in tqdm(range(freset.shape[0])):\n",
    "    filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+freset['image'][i]\n",
    "    if not freset['POutc'][i]==8:\n",
    "        try:\n",
    "            im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "            im = cv2.resize(im,(pixel,pixel))\n",
    "            im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "            #im = cv2.copyMakeBorder(im, 32, 32, 0, 0, cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "            img = img_to_array(im)\n",
    "            fine_image.append(img)\n",
    "            fine_label.append(decodepreg(freset['POutc'][i]))\n",
    "        except:\n",
    "            print(filename)\n",
    "\n",
    "a0= [x for x, y in list(enumerate(fine_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(fine_label)) if y ==1]\n",
    "print(len(a0),len(a1))\n",
    "xxfine = np.array(fine_image,dtype='float32')\n",
    "yyfine = np.array(fine_label)\n",
    "\n",
    "index = [i for i in range(len(xxfine))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xfine = xxfine[index]\n",
    "yfine = yyfine[index]\n",
    "\n",
    "RANDOM_SEED = 27\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "sfolder=StratifiedKFold(n_splits=10,shuffle=True,random_state=27)\n",
    "print(sfolder)\n",
    "\n",
    "testindex=[test for train, test in sfolder.split(xfine,yfine)]\n",
    "trainindex=[train for train, test in sfolder.split(xfine,yfine)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6164f110-2ca8-4cc3-9e92-eef31709b62d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "    checkpoint_filepath = '/mnt/louisayu/nfs_share2/embryo/model_weights/preg_fre/ep{epoch:03d}_acc{accuracy:.4f}_val_loss{loss:.4f}.h5'\n",
    "    return [\n",
    "            EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience = 13, verbose=1, restore_best_weights=True),\n",
    "            \n",
    "            ReduceLROnPlateau(monitor=\"val_aucc\", mode=\"max\", factor=0.6, min_lr=1e-6, patience=5, verbose=1),\n",
    "            \n",
    "            ModelCheckpoint(checkpoint_filepath, monitor=\"val_aucc\", mode=\"max\", save_weights_only=True, save_best_only=False)\n",
    "           ]\n",
    "\n",
    "def vitmodel():\n",
    "    vit_model = vit.vit_b16(\n",
    "        image_size = 256,\n",
    "        activation = 'linear',\n",
    "        pretrained = True,\n",
    "        include_top = True,\n",
    "        pretrained_top =True,)\n",
    "\n",
    "    input_tensor = layers.Input(shape=(pixel,pixel,channels),name='vitinput')\n",
    "    # re=tf.keras.layers.Resizing(224,224,name='vitresize')(input_tensor)\n",
    "    i1=layers.RandomRotation(factor=(-0.4, -0.2))(input_tensor)\n",
    "    # i2=layers.RandomZoom(height_factor=-0.1, width_factor=-0.1)(i1)\n",
    "    i3=layers.RandomFlip(mode=\"horizontal_and_vertical\")(i1)\n",
    "    i4=layers.BatchNormalization()(i3)\n",
    "    conv_base = vit_model(i4)\n",
    "    o1=layers.Dense(64,activation='tanh')(conv_base)\n",
    "    output_tensor=layers.Dense(1,activation='sigmoid')(o1)\n",
    "    model=tf.keras.models.Model(input_tensor,output_tensor)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00874bba-6ea4-417e-ac64-cc1bcc50f336",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8548840477863668, 1: 1.2044554455445544}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 22:42:29.802048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 36591 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:c7:00.0, compute capability: 8.0\n",
      "/mnt/louisayu/nfs_share2/anaconda3/envs/tf/lib/python3.7/site-packages/vit_keras/utils.py:83: UserWarning: Resizing position embeddings from 24, 24 to 16, 16\n",
      "  UserWarning,\n",
      "2024-03-06 22:42:42.309867: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 22:43:17.394495: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n",
      "2024-03-06 22:43:30.448391: W tensorflow/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2024-03-06 22:43:30.448482: W tensorflow/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-03-06 22:43:30.448806: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-03-06 22:43:32.995009: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 - 98s - loss: 0.7030 - accuracy: 0.5572 - aucc: 0.5719 - val_loss: 1.1357 - val_accuracy: 0.3904 - val_aucc: 0.4839\n",
      "Epoch 2/80\n",
      "27/27 - 21s - loss: 0.6767 - accuracy: 0.5750 - aucc: 0.6107 - val_loss: 0.7148 - val_accuracy: 0.5068 - val_aucc: 0.5487\n",
      "Epoch 3/80\n",
      "27/27 - 23s - loss: 0.6662 - accuracy: 0.5988 - aucc: 0.6351 - val_loss: 0.6956 - val_accuracy: 0.5651 - val_aucc: 0.6174\n",
      "Epoch 4/80\n",
      "27/27 - 22s - loss: 0.6532 - accuracy: 0.5983 - aucc: 0.6572 - val_loss: 0.7287 - val_accuracy: 0.5240 - val_aucc: 0.6275\n",
      "Epoch 5/80\n",
      "27/27 - 28s - loss: 0.6503 - accuracy: 0.6095 - aucc: 0.6605 - val_loss: 0.7003 - val_accuracy: 0.5822 - val_aucc: 0.6316\n",
      "Epoch 6/80\n",
      "27/27 - 31s - loss: 0.6501 - accuracy: 0.6137 - aucc: 0.6672 - val_loss: 0.8008 - val_accuracy: 0.4212 - val_aucc: 0.6249\n",
      "Epoch 7/80\n",
      "27/27 - 30s - loss: 0.6421 - accuracy: 0.6263 - aucc: 0.6746 - val_loss: 0.7465 - val_accuracy: 0.5137 - val_aucc: 0.6286\n",
      "Epoch 8/80\n",
      "27/27 - 31s - loss: 0.6161 - accuracy: 0.6432 - aucc: 0.7136 - val_loss: 0.7265 - val_accuracy: 0.5411 - val_aucc: 0.6439\n",
      "Epoch 9/80\n",
      "27/27 - 24s - loss: 0.6039 - accuracy: 0.6558 - aucc: 0.7270 - val_loss: 0.7257 - val_accuracy: 0.5514 - val_aucc: 0.6237\n",
      "Epoch 10/80\n",
      "27/27 - 26s - loss: 0.5891 - accuracy: 0.6749 - aucc: 0.7465 - val_loss: 0.7080 - val_accuracy: 0.5479 - val_aucc: 0.6359\n",
      "Epoch 11/80\n",
      "27/27 - 24s - loss: 0.5730 - accuracy: 0.6922 - aucc: 0.7639 - val_loss: 0.7561 - val_accuracy: 0.5479 - val_aucc: 0.6210\n",
      "Epoch 12/80\n",
      "27/27 - 26s - loss: 0.5670 - accuracy: 0.6950 - aucc: 0.7706 - val_loss: 0.8045 - val_accuracy: 0.4726 - val_aucc: 0.6113\n",
      "Epoch 13/80\n",
      "27/27 - 23s - loss: 0.5503 - accuracy: 0.7039 - aucc: 0.7901 - val_loss: 0.7064 - val_accuracy: 0.6062 - val_aucc: 0.5952\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.7999999545281754e-05.\n",
      "Epoch 14/80\n",
      "27/27 - 26s - loss: 0.5003 - accuracy: 0.7431 - aucc: 0.8346 - val_loss: 0.7996 - val_accuracy: 0.5788 - val_aucc: 0.5878\n",
      "Epoch 15/80\n",
      "27/27 - 24s - loss: 0.4874 - accuracy: 0.7562 - aucc: 0.8452 - val_loss: 0.8493 - val_accuracy: 0.5342 - val_aucc: 0.5800\n",
      "Epoch 16/80\n",
      "27/27 - 24s - loss: 0.4788 - accuracy: 0.7562 - aucc: 0.8512 - val_loss: 0.8159 - val_accuracy: 0.6301 - val_aucc: 0.5968\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "0.5481301001662993\n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "Y_train = ytrain\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(Y_train), y=Y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "\n",
    "\n",
    "model=vitmodel()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00003)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc')]) \n",
    "history=model.fit(x=X_train, y= Y_train, validation_split=0.12, batch_size= 80, epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "y_prediction=model.predict(np.reshape(xfine,(len(xfine),pixel,pixel,channels)))\n",
    "auc = roc_auc_score(yfine, y_prediction)\n",
    "print(auc)\n",
    "newdir='/mnt/louisayu/nfs_share2/embryo/model_weights/preg_fre/'+str(auc).replace('0.','')\n",
    "os.mkdir('/mnt/louisayu/nfs_share2/embryo/model_weights/preg_fre/'+str(auc).replace('0.',''))\n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/preg_fre/'+str(auc).replace('0.','')+'/'+str(auc).replace('0.','frebasemodel_')+'.h5')\n",
    "for i in range(0,10):\n",
    "    os.mkdir('/mnt/louisayu/nfs_share2/embryo/model_weights/preg_fre/'+str(auc).replace('0.','')+'/'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42974227-2e56-4cb6-bebc-62370b29b15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5483870967741935\n",
      "0.5977229601518026\n",
      "0.5370018975332068\n",
      "0.50853889943074\n",
      "0.42884250474383306\n",
      "0.5443548387096775\n",
      "0.5215686274509804\n",
      "0.6176470588235293\n",
      "0.5372549019607844\n",
      "0.6176470588235294\n"
     ]
    }
   ],
   "source": [
    "# bp=[]\n",
    "# for i in range(0,10):\n",
    "#     ac=roc_auc_score(yfine[testindex[i]], model.predict(xfine[testindex[i]]))\n",
    "#     print(ac)\n",
    "#     bp.append(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38bda5d-f836-4773-8369-8a1c49c5bb49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foldi=0\n",
    "for foldi in range(0,10):\n",
    "    def get_callbacks():\n",
    "        checkpoint_filepath = '/mnt/louisayu/nfs_share2/embryo/model_weights/preg_fre/finetuningmodel/ep{epoch:03d}_acc{accuracy:.4f}_val_loss{loss:.4f}.h5'\n",
    "        return [\n",
    "                EarlyStopping(monitor=\"aucc\", mode=\"max\", patience = 5, verbose=1, restore_best_weights=True),\n",
    "\n",
    "                ReduceLROnPlateau(monitor=\"aucc\", mode=\"max\", factor=0.6, min_lr=1e-6, patience=2, verbose=1),\n",
    "\n",
    "                ModelCheckpoint(checkpoint_filepath, monitor=\"aucc\", mode=\"max\", save_weights_only=True, save_best_only=False)]\n",
    "\n",
    "    X_fine = np.reshape(xfine[trainindex[foldi]],(len(xfine[trainindex[foldi]]),pixel,pixel,channels))\n",
    "    Y_fine = yfine[trainindex[foldi]]\n",
    "\n",
    "    model=tf.keras.models.load_model(newdir+'/'+str(auc).replace('0.','frebasemodel_')+'.h5',compile=False)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "    model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc')]) \n",
    "    history=model.fit(x=X_fine, y= Y_fine, batch_size= 80, epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "\n",
    "    y_prediction=model.predict(xfine[testindex[foldi]])\n",
    "    fineauc = roc_auc_score(yfine[testindex[foldi]], y_prediction)\n",
    "    print(\"mary roc_auc_score:\",fineauc)\n",
    "    pr= average_precision_score(yfine[testindex[foldi]], y_prediction)\n",
    "    print(\"mary pr_auc_score :\",pr)\n",
    "\n",
    "\n",
    "    model.save(newdir+'/'+str(foldi)+'/'+str(fineauc).replace('0.','')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7584010-8c88-4355-8f83-9883dfbe8987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.707186907020873"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tenfold=[]\n",
    "\n",
    "for foldi in range(0,10):\n",
    "    transform= [float((str('0.')+str(foldauc)).replace('.h5','')) for foldauc in os.listdir(newdir+'/'+str(foldi)+'/')]\n",
    "    tenfold.append(transform)\n",
    "    \n",
    "meanauc =0 if len(tenfold) == 0 else sum(tenfold)/len(tenfold)\n",
    "meanauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b64ee1-0196-4a7e-9053-053046c60d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true=[]\n",
    "pred=[]\n",
    "pred_acc=[]\n",
    "for foldi in range(0,10):\n",
    "    weightsdir=newdir+'/'+str(foldi)+'/'+str(tenfold[foldi]).replace('0.','')+'.h5'\n",
    "    X_test = np.reshape(xfine[testindex[foldi]],(len(xfine[testindex[foldi]]),pixel,pixel,channels))\n",
    "    model=tf.keras.models.load_model(weightsdir)\n",
    "    true.extend(yfine[testindex[foldi]])\n",
    "    pred.extend(model.predict(X_test)[:,0])\n",
    "    pred_acc.append(accuracy_score(yfine[testindex[foldi]],np.where(model.predict(X_test)[:,0] >= 0.5, 1, 0)))\n",
    "\n",
    "\n",
    "def plot_roc_curve(fpr, tpr,score):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve: '+str(score))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "score=roc_auc_score(true, pred)\n",
    "fpr, tpr, thresholds = roc_curve(true, pred)\n",
    "plot_roc_curve(fpr, tpr,score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
