{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1303be-e14d-4877-8ba4-63de1dd16686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/louisayu/nfs_share2/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n",
      "2024-03-25 22:49:55.594802: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-25 22:49:56.845163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19045 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:85:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow_addons as tfa\n",
    "#import keras\n",
    "import time\n",
    "#time.sleep(60*60*8)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, regularizers, layers, optimizers, losses, metrics\n",
    "from tensorflow.keras.layers import Input, Concatenate, Conv2D, Flatten, Dense, Add, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator,array_to_img\n",
    "from keras import backend\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_score, recall_score, classification_report, ConfusionMatrixDisplay, roc_auc_score, matthews_corrcoef,plot_roc_curve,roc_curve,average_precision_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "from skimage import data, color, img_as_ubyte ,io\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import hough_ellipse\n",
    "from skimage.draw import ellipse_perimeter\n",
    "from skimage.color import rgb2gray,rgba2rgb\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import mode\n",
    "import imutils\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "import random\n",
    "import urllib.request\n",
    "from vit_keras import vit\n",
    "import csv\n",
    "import random\n",
    "def decode(a):\n",
    "    if a =='A' or a =='2':\n",
    "        return int(2)\n",
    "    elif  a=='B' or a == '1':\n",
    "        return int(1)\n",
    "    elif a=='C' or a =='0':\n",
    "        return int(0)\n",
    "    else:\n",
    "        return int(a)\n",
    "def flatten_extend(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "         flat_list.extend(row)\n",
    "    return flat_list\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "# tf.compat.v1.set_random_seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d718fa6c-8979-4efc-a7c6-37dde2e9f575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1489\n",
      "148\n",
      "148\n",
      "148\n",
      "148\n",
      "148\n",
      "148\n",
      "148\n",
      "148\n",
      "148\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "preglist=os.listdir('/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/')\n",
    "\n",
    "def split_list(lst, chunk_size):\n",
    "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
    "print(len(preglist))\n",
    "for i in range(10):\n",
    "    print(len(split_list(preglist,len(preglist)//10)[i]))\n",
    "\n",
    "test0=split_list(preglist,len(preglist)//10)[0]\n",
    "train0=list(set(preglist)-set(test0))\n",
    "train0.extend(split_list(preglist,len(preglist)//10)[10])\n",
    "test1=split_list(preglist,len(preglist)//10)[1]\n",
    "train1=list(set(preglist)-set(test1))\n",
    "train1.extend(split_list(preglist,len(preglist)//10)[10])\n",
    "test2=split_list(preglist,len(preglist)//10)[2]\n",
    "train2=list(set(preglist)-set(test2))\n",
    "train2.extend(split_list(preglist,len(preglist)//10)[10])\n",
    "test3=split_list(preglist,len(preglist)//10)[3]\n",
    "train3=list(set(preglist)-set(test3))\n",
    "train3.extend(split_list(preglist,len(preglist)//10)[10])\n",
    "test4=split_list(preglist,len(preglist)//10)[4]\n",
    "train4=list(set(preglist)-set(test4))\n",
    "train4.extend(split_list(preglist,len(preglist)//10)[10])\n",
    "test5=split_list(preglist,len(preglist)//10)[5]\n",
    "train5=list(set(preglist)-set(test5))\n",
    "train5.extend(split_list(preglist,len(preglist)//10)[10])\n",
    "test6=split_list(preglist,len(preglist)//10)[6]\n",
    "train6=list(set(preglist)-set(test6))\n",
    "train6.extend(split_list(preglist,len(preglist)//10)[10])\n",
    "test7=split_list(preglist,len(preglist)//10)[7]\n",
    "train7=list(set(preglist)-set(test7))\n",
    "train7.extend(split_list(preglist,len(preglist)//10)[10])\n",
    "test8=split_list(preglist,len(preglist)//10)[8]\n",
    "train8=list(set(preglist)-set(test8))\n",
    "train8.extend(split_list(preglist,len(preglist)//10)[10])\n",
    "test9=split_list(preglist,len(preglist)//10)[9]\n",
    "train9=list(set(preglist)-set(test9))\n",
    "train9.extend(split_list(preglist,len(preglist)//10)[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51bc5fc1-cf9f-4814-89f2-885bb00a7cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pixel=256\n",
    "channels=3\n",
    "NUM_CLASSES=2\n",
    "\n",
    "def modelfro():\n",
    "    vit_model = vit.vit_l16(\n",
    "            image_size = pixel,\n",
    "            activation = 'linear',\n",
    "            pretrained = True,\n",
    "            include_top = True,\n",
    "            pretrained_top =False,)\n",
    "\n",
    "    input_tensor = layers.Input(shape=(pixel,pixel,channels),name='vitinput')\n",
    "    re=tf.keras.layers.Resizing(pixel,pixel,name='vitresize')(input_tensor)\n",
    "    i1=layers.RandomRotation(factor=(-0.4, -0.2))(re)\n",
    "    # i2=layers.RandomZoom(height_factor=-0.1, width_factor=-0.1)(i1)\n",
    "    i3=layers.RandomFlip(mode=\"horizontal_and_vertical\")(i1)\n",
    "    bn=layers.BatchNormalization()(i3)\n",
    "    conv_base = vit_model(bn)\n",
    "    o1=layers.Dense(196,activation='elu',name='vitdense1')(conv_base)\n",
    "    output=layers.Dropout(0.3)(o1)\n",
    "    lb= tf.keras.models.Model(input_tensor ,output)\n",
    "    \n",
    "    input_g1 = layers.Input(shape=(1),name='G1')\n",
    "    ig1=layers.Dense(1,activation='linear')(input_g1)\n",
    "    mf1= tf.keras.models.Model(input_g1,ig1)\n",
    "    \n",
    "    input_g2 = layers.Input(shape=(1),name='G2')\n",
    "    ig2=layers.Dense(1,activation='linear')(input_g2)\n",
    "    mf2= tf.keras.models.Model(input_g2,ig2)\n",
    "    \n",
    "    input_g3 = layers.Input(shape=(1),name='G3')\n",
    "    ig3=layers.Dense(1,activation='linear')(input_g3)\n",
    "    mf3= tf.keras.models.Model(input_g3,ig3)\n",
    "\n",
    "    x = Concatenate()([mf1.output,mf2.output,mf3.output,lb.output])  \n",
    "    x = layers.Dense(32,activation='tanh')(x)\n",
    "\n",
    "    output_tensor=layers.Dense(1,activation='sigmoid')(x)\n",
    "    model=tf.keras.models.Model([mf1.input,mf2.input,mf3.input,lb.input],output_tensor)\n",
    "    return model\n",
    "\n",
    "def get_callbacks():\n",
    "    checkpoint_filepath = '/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/ep{epoch:03d}_acc{accuracy:.4f}_val_loss{loss:.4f}.h5'\n",
    "    return [\n",
    "            EarlyStopping(\"val_accuracy\", mode=\"max\", patience = 13, verbose=1, restore_best_weights=True),\n",
    "            \n",
    "            ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.6, min_lr=1e-6, patience=5, verbose=1),\n",
    "            \n",
    "            ModelCheckpoint(checkpoint_filepath, monitor=\"val_loss\", mode=\"min\", save_weights_only=True, save_best_only=True)\n",
    "           ]\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def expect_f1(y_prob, thres):\n",
    "    idxs = np.where(y_prob >= thres)[0]\n",
    "    tp = y_prob[idxs].sum()\n",
    "    fp = len(idxs) - tp\n",
    "    idxs = np.where(y_prob < thres)[0]\n",
    "    fn = y_prob[idxs].sum()\n",
    "    return 2*tp / (2*tp + fp + fn)\n",
    "\n",
    "def optimal_threshold(y_prob):\n",
    "    y_prob = np.sort(y_prob)[::-1]\n",
    "    f1s = [expect_f1(y_prob, p) for p in y_prob]\n",
    "    thres = y_prob[np.argmax(f1s)]\n",
    "    return thres, f1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ea8f5-1159-429f-bd59-f104fae92edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train0:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "history=model.fit(x=[G1train,G2train,G3train,Xtrain], y= Ytrain, batch_size=32, validation_data=([G1val,G2val,G3val,Xval],Yval) , epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "#input test img and label\n",
    "\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "for f in test0:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold0_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final0_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62d3e8-e3a8-4acf-b843-9606a34b79c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train1:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "history=model.fit(x=[G1train,G2train,G3train,Xtrain], y= Ytrain, batch_size=32, validation_data=([G1val,G2val,G3val,Xval],Yval) , epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "\n",
    "\n",
    "#calculate optimal threshold by f1\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "\n",
    "#input test img and label\n",
    "\n",
    "for f in test1:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold1_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "    \n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final1_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3858f7-435a-4317-a2eb-efd36a57039e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train2:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "history=model.fit(x=[G1train,G2train,G3train,Xtrain], y= Ytrain, batch_size=32, validation_data=([G1val,G2val,G3val,Xval],Yval) , epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "\n",
    "\n",
    "#calculate optimal threshold by f1\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "\n",
    "#input test img and label\n",
    "for f in test2:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold2_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "    \n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final2_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e87a0-6703-4dec-ac12-0966513f29a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train3:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "history=model.fit(x=[G1train,G2train,G3train,Xtrain], y= Ytrain, batch_size=32, validation_data=([G1val,G2val,G3val,Xval],Yval) , epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "\n",
    "#calculate optimal threshold by f1\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "\n",
    "#input test img and label\n",
    "for f in test3:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold3_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "    \n",
    "    \n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final3_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3618f8-c9b0-4b4a-82b9-b4dc680830d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train4:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "history=model.fit(x=[G1train,G2train,G3train,Xtrain], y= Ytrain, batch_size=32, validation_data=([G1val,G2val,G3val,Xval],Yval) , epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "\n",
    "\n",
    "#calculate optimal threshold by f1\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "\n",
    "#input test img and label\n",
    "\n",
    "for f in test4:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold4_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "    \n",
    "    \n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final4_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea3096-ef0f-4285-9f11-1611f9ad2361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train5:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "history=model.fit(x=[G1train,G2train,G3train,Xtrain], y= Ytrain, batch_size=32, validation_data=([G1val,G2val,G3val,Xval],Yval) , epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "\n",
    "#calculate optimal threshold by f1\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "\n",
    "#input test img and label\n",
    "\n",
    "\n",
    "for f in test5:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold5_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "    \n",
    "    \n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final5_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f4725-e060-4e53-9b73-dff01e59fa3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train6:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "history=model.fit(x=[G1train,G2train,G3train,Xtrain], y= Ytrain, batch_size=32, validation_data=([G1val,G2val,G3val,Xval],Yval) , epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "\n",
    "#calculate optimal threshold by f1\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "\n",
    "#input test img and label\n",
    "\n",
    "for f in test6:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold6_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "    \n",
    "    \n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final6_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f6c6b-5365-4304-bf68-3f6d82ed98c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train7:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "history=model.fit(x=[G1train,G2train,G3train,Xtrain], y= Ytrain, batch_size=32, validation_data=([G1val,G2val,G3val,Xval],Yval) , epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "\n",
    "#calculate optimal threshold by f1\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "\n",
    "#input test img and label\n",
    "for f in test7:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold7_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "    \n",
    "            \n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final7_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a01b5-6ec6-4e17-9e61-3ef903846f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train8:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "\n",
    "#calculate optimal threshold by f1\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "\n",
    "#input test img and label\n",
    "\n",
    "for f in test8:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold8_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "    \n",
    "            \n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final8_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d88a9ad-2c12-4fae-841f-02b09f6f740d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image=[]\n",
    "train_label=[]\n",
    "G1=[]\n",
    "G2=[]\n",
    "G3=[]\n",
    "#input training img and label\n",
    "for f in train9:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        train_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "        G1.append(int(p['G1'][i])-1)\n",
    "        G2.append(decode(p['G2'][i]))\n",
    "        G3.append(decode(p['G3'][i]))\n",
    "\n",
    "a0= [x for x, y in list(enumerate(train_label)) if y ==0]\n",
    "a1= [x for x, y in list(enumerate(train_label)) if y ==1]\n",
    "print(len(a0),len(a1))   \n",
    "\n",
    "#preprocess input\n",
    "xxtrain = np.array(train_image,dtype='float32')\n",
    "yytrain = np.array(train_label)\n",
    "xxG1=np.array(G1,dtype='float32')\n",
    "xxG2=np.array(G2,dtype='float32')\n",
    "xxG3=np.array(G3,dtype='float32')\n",
    "index = [i for i in range(len(xxtrain))]\n",
    "np.random.seed(27)\n",
    "np.random.shuffle(index)\n",
    "xtrain = xxtrain[index]\n",
    "ytrain = yytrain[index]\n",
    "G11=xxG1[index]\n",
    "G22=xxG2[index]\n",
    "G33=xxG3[index]\n",
    "x_train = np.reshape(xtrain,(len(xtrain),pixel,pixel,channels))\n",
    "y_train = ytrain\n",
    "G1x_train = np.reshape(G11,(len(G11),1))\n",
    "G2x_train = np.reshape(G22,(len(G22),1))\n",
    "G3x_train = np.reshape(G33,(len(G33),1))\n",
    "\n",
    "\n",
    "#split train/val\n",
    "index = [i for i in range(len(x_train))]\n",
    "random.seed(27)\n",
    "valindex=random.sample(index ,int(len(index)*0.15))\n",
    "trainindex=list(set(index).difference(set(valindex)))\n",
    "Xval=x_train[valindex]\n",
    "Yval=y_train[valindex]\n",
    "G1val=G1x_train[valindex]\n",
    "G2val=G2x_train[valindex]\n",
    "G3val=G3x_train[valindex]\n",
    "Xtrain=x_train[trainindex]\n",
    "Ytrain=y_train[trainindex]\n",
    "G1train=G1x_train[trainindex]\n",
    "G2train=G2x_train[trainindex]\n",
    "G3train=G3x_train[trainindex]\n",
    "\n",
    "#fit model\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "print(d_class_weights)\n",
    "model = modelfro()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "model.compile(optimizer=opt,  loss=tf.keras.losses.binary_crossentropy, metrics =['accuracy', tf.keras.metrics.AUC(multi_label = False, name='aucc'),get_f1])\n",
    "history=model.fit(x=[G1train,G2train,G3train,Xtrain], y= Ytrain, batch_size=32, validation_data=([G1val,G2val,G3val,Xval],Yval) , epochs=80, verbose=2, shuffle=True ,callbacks=get_callbacks(), class_weight=d_class_weights)\n",
    "\n",
    "#calculate optimal threshold by f1\n",
    "y_true=Yval\n",
    "y_scores=model.predict([G1val,G2val,G3val,Xval])\n",
    "trues, preds = calibration_curve(y_true, y_scores, n_bins=5)\n",
    "plt.plot(preds, trues, marker='o')\n",
    "plt.xlabel(\"Posterior\")\n",
    "plt.ylabel(\"Probability being positive in each bin\")\n",
    "plt.xlim(([0, 1]))\n",
    "plt.ylim(([0, 1]))\n",
    "plt.title(\"Calibration plot\")\n",
    "thres2, f1s = optimal_threshold(y_scores)\n",
    "print(\"Predicted Optimal Threshold is\" ,thres2,\" with F1 score:\",expect_f1(y_scores, thres2))\n",
    "\n",
    "\n",
    "#input test img and label\n",
    "\n",
    "for f in test9:\n",
    "    p=pd.read_excel(r'/mnt/louisayu/nfs_share2/embryo/code/em_aug/ACC/'+f, engine='openpyxl')\n",
    "    test_label=[]\n",
    "    test_image=[]\n",
    "    tG1=[]\n",
    "    tG2=[]\n",
    "    tG3=[]\n",
    "    for i in range(p.shape[0]):\n",
    "        filename= \"/mnt/louisayu/nfs_share2/embryo/preprocess_rec_1018/\"+p['image'][i]\n",
    "        im = cv2.imread(filename)#,cv2.IMREAD_GRAYSCALE)\n",
    "        im = cv2.resize(im,(pixel,pixel))\n",
    "        im = cv2.normalize(im, None, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "        img = img_to_array(im)\n",
    "        test_image.append(img)\n",
    "        if p['LBOutc1'][i]==7:\n",
    "            test_label.append(1)\n",
    "        else:\n",
    "            test_label.append(0)\n",
    "\n",
    "        tG1.append(int(p['G1'][i])-1)\n",
    "        tG2.append(decode(p['G2'][i]))\n",
    "        tG3.append(decode(p['G3'][i]))\n",
    "\n",
    "    xtest_arr = np.array(test_image,dtype='float32')\n",
    "    ytest_arr = np.array(test_label)\n",
    "    tG1_arr=np.array(tG1,dtype='float32')\n",
    "    tG2_arr=np.array(tG2,dtype='float32')\n",
    "    tG3_arr=np.array(tG3,dtype='float32')\n",
    "    x_test = np.reshape(xtest_arr,(len(xtest_arr),pixel,pixel,channels))\n",
    "    y_test = ytest_arr\n",
    "    G1x_test = np.reshape(tG1_arr,(len(tG1_arr),1))\n",
    "    G2x_test = np.reshape(tG2_arr,(len(tG2_arr),1))\n",
    "    G3x_test = np.reshape(tG3_arr,(len(tG3_arr),1))\n",
    "    y_pred=model.predict([G1x_test,G2x_test,G3x_test,x_test])\n",
    "    y_pred_after_thre= np.where(y_pred>=thres2,1,0)\n",
    "    with open(\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/fold9_\"+f, \"w\", newline='') as csvfile:\n",
    "        \n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['true','pred','pred_thre'])\n",
    "        for j in range(len(y_test)):\n",
    "            content = [y_test[j], y_pred[j][0], y_pred_after_thre[j][0]]\n",
    "            writer.writerow(content)\n",
    "    \n",
    "    \n",
    "model.save('/mnt/louisayu/nfs_share2/embryo/model_weights/lb_fro/fro/model/'+str(thres2).replace('0.','final9_')+'.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5436c764-540e-4800-ae82-30a0a83af947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "148\n",
      "top1accuracy for  0 -th fold: 0.8095238095238095\n",
      "1\n",
      "148\n",
      "top1accuracy for  1 -th fold: 0.6666666666666666\n",
      "2\n",
      "148\n",
      "top1accuracy for  2 -th fold: 0.5526315789473685\n",
      "3\n",
      "148\n",
      "top1accuracy for  3 -th fold: 0.5833333333333334\n",
      "4\n",
      "148\n",
      "top1accuracy for  4 -th fold: 0.5714285714285714\n",
      "5\n",
      "148\n",
      "top1accuracy for  5 -th fold: 0.5833333333333334\n",
      "6\n",
      "148\n",
      "top1accuracy for  6 -th fold: 0.625\n",
      "7\n",
      "148\n",
      "top1accuracy for  7 -th fold: 0.5172413793103449\n",
      "8\n",
      "148\n",
      "top1accuracy for  8 -th fold: 0.5769230769230769\n",
      "9\n",
      "148\n",
      "top1accuracy for  9 -th fold: 0.5238095238095238\n"
     ]
    }
   ],
   "source": [
    "resultdir=\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/\"\n",
    "for i in range(0,10):\n",
    "    ranking=0\n",
    "    multisuccess_patients=0\n",
    "    pati_list=[j for j in os.listdir(resultdir) if 'fold'+str(i) in j]\n",
    "    for k in pati_list:\n",
    "        p=pd.read_csv(resultdir+k)\n",
    "        if p.shape[0]>1 and 1 in list(p['true']):\n",
    "            multisuccess_patients=multisuccess_patients+1\n",
    "            if p['true'][np.argmax(p['pred'])]==1:\n",
    "                ranking=ranking+1\n",
    "            else:\n",
    "                continue\n",
    "    print(\"top1accuracy for \",i,\"-th fold:\", ranking/multisuccess_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33fc5846-3690-40c1-bd31-2cd24cb44d03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1accuracy for  0 -th fold: 0.6418918918918919\n",
      "top1accuracy for  1 -th fold: 0.5202702702702703\n",
      "top1accuracy for  2 -th fold: 0.5202702702702703\n",
      "top1accuracy for  3 -th fold: 0.5067567567567568\n",
      "top1accuracy for  4 -th fold: 0.5608108108108109\n",
      "top1accuracy for  5 -th fold: 0.5878378378378378\n",
      "top1accuracy for  6 -th fold: 0.6081081081081081\n",
      "top1accuracy for  7 -th fold: 0.6013513513513513\n",
      "top1accuracy for  8 -th fold: 0.5337837837837838\n",
      "top1accuracy for  9 -th fold: 0.6081081081081081\n"
     ]
    }
   ],
   "source": [
    "resultdir=\"/mnt/louisayu/nfs_share2/embryo/code/final/fropredict/result/lbprob_imgfro/\"\n",
    "for i in range(0,10):\n",
    "    multisuccess_truepred=0\n",
    "    multifail_truepred=0\n",
    "    singlesuccess_truepred=0\n",
    "    singfail_truepred=0\n",
    "    multisuccess_patients=0\n",
    "    multifail_patients=0\n",
    "    singlesuccess_patients=0\n",
    "    singfail_patients=0\n",
    "    pati_list=[j for j in os.listdir(resultdir) if 'fold'+str(i) in j]\n",
    "    for k in pati_list:\n",
    "        p=pd.read_csv(resultdir+k)\n",
    "        if p.shape[0]>1 and 1 in list(p['true']):\n",
    "            multisuccess_patients=multisuccess_patients+1\n",
    "            if p['true'][np.argmax(p['pred'])]==1 and p['pred_thre'][np.argmax(p['pred'])]==1:\n",
    "                multisuccess_truepred=multisuccess_truepred+1\n",
    "            else:\n",
    "                continue\n",
    "        elif p.shape[0]>1 and 1 not in list(p['true']):\n",
    "            multifail_patients=multifail_patients+1\n",
    "            if p['true'][np.argmax(p['pred'])]==0 and p['pred_thre'][np.argmax(p['pred'])]==0:\n",
    "                multifail_truepred=multifail_truepred+1     \n",
    "            else:\n",
    "                continue\n",
    "        elif p.shape[0]==1 and 1 not in list(p['true']):\n",
    "            singfail_patients=singfail_patients+1\n",
    "            if p['true'][np.argmax(p['pred'])]==0 and p['pred_thre'][np.argmax(p['pred'])]==0:\n",
    "                singfail_truepred=singfail_truepred+1     \n",
    "            else:\n",
    "                continue\n",
    "        elif p.shape[0]==1 and 1 in list(p['true']):\n",
    "            singlesuccess_patients=singlesuccess_patients+1\n",
    "            if p['true'][np.argmax(p['pred'])]==1 and p['pred_thre'][np.argmax(p['pred'])]==1:\n",
    "                singlesuccess_truepred=singlesuccess_truepred+1     \n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"top1accuracy for \",i,\"-th fold:\", (multisuccess_truepred+multifail_truepred+singlesuccess_truepred+singfail_truepred)/(multisuccess_patients+multifail_patients+singlesuccess_patients+singfail_patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c62cc-2676-4f05-b536-9a996047ba76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc72071-1326-4783-9209-a6f146a7c6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
